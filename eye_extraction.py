# -*- coding: utf-8 -*-
"""Eye extraction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10DKVuX-AA22m8WAYPSBx70G61sLT163_

This is the code for extracting eyes from the face images generated by text to image models.
"""

from google.colab import drive
drive.mount('/content/drive/')

from keras.models import load_model
!pip install mtcnn
# confirm mtcnn was installed correctly
import mtcnn
# print version
print(mtcnn.__version__)

import numpy as np
from mtcnn.mtcnn import MTCNN
from numpy import asarray
#!pip install pycocotools
import io
import os
from pycocotools.coco import COCO
from PIL import Image
import matplotlib.pyplot as plt


# Simple python package to shut up Tensorflow warnings and logs.
!pip install silence_tensorflow
import silence_tensorflow.auto

#set up folders for extracted faces and the corresponding captions
# initialize COCO API for instance annotations
import os
# dataDir = './'

# image_folder = "extracted_eyes"

# savedirimage = dataDir +  image_folder + "/"
savedirimage='/content/drive/MyDrive/Project-AML/LAFITE_Flickr30k/Flickr30_LAFITE_Extracted_eyes'# the path to save the extracted eyes images


if not os.path.exists(savedirimage):
	os.makedirs(savedirimage)

# extract eyes from extracted_face_image
def extract_eyes_from_extratced_face(filename, img_name, required_size = (300,100),left_eye_corner = 20, right_eye_corner = 230):
    # load image from file
    image = Image.open(filename)
    # convert to RGB, if needed
    image = image.convert('RGB')
    # convert to array
    pixels = np.asarray(image)
    # create the detector, using default weights
    detector = MTCNN()
    # detect faces in the image
    results = detector.detect_faces(pixels)
    if len(results)>=1:
        left_right_eye_x_diff = results[0]['keypoints']['right_eye'][0] - results[0]['keypoints']['left_eye'][0]
        left_right_eye_y_diff = abs(results[0]['keypoints']['right_eye'][1] - results[0]['keypoints']['left_eye'][1])
    else:
        return False
    # extract the bounding box from the first face
    if left_right_eye_x_diff>=100 and left_right_eye_y_diff < 8:
        xeye = left_eye_corner
        yeye = int((results[0]['keypoints']['left_eye'][1]+results[0]['keypoints']['right_eye'][1])/2 -10)
        width = right_eye_corner
        height = int((yeye+results[0]['keypoints']['nose'][1])/2)
        eyes = pixels[yeye:height, xeye:width]
        # resize pixels to the model size
        image = Image.fromarray(eyes)
        image = image.resize(required_size)
        eyes_array = np.asarray(image)
        plt.imsave(os.path.join(savedirimage, img_name),eyes_array)
        return True
    return False

files = os.listdir('/content/drive/MyDrive/Project-AML/LAFITE_Flickr30_face')

len(files)

index =0
for file in files[index:10000]:
    if extract_eyes_from_extratced_face(os.path.join('/content/drive/MyDrive/Project-AML/LAFITE_Flickr30_face',file), file):
        print(index)
        index+=1


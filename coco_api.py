# -*- coding: utf-8 -*-
"""COCO API.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1j-hJ1ABbHQVyj4vC_w7znZrtJKhGNqLF
"""

import os
from pycocotools.coco import COCO
import numpy as np
import skimage.io as io
#import matplotlib.pyplot as plt
#from PIL import Image, ImageDraw
#from PIL import ImageFont
import cv2
import sys
import json

def loadImageandCaption(img_id,imageindex,low_res = 512):
    img = coco.loadImgs(img_id)[0]
    url = img['coco_url']

    tokenlist = url.split('/')
    #print(tokenlist)

    # print URL and visualize corresponding image
    #print(url)
    fname = tokenlist[4]

    try:
    	image = cv2.imread(os.path.join(image_src_Coco,fname))
    	#image = io.imread(url)
    except:
    	print(f"{fname} was not found in directory")
    	return 0

    #plt.axis('off')
    #plt.imshow(image)
    #plt.show()

    #f_name = captionsjson['images'][img_id]['file_name']

    savefilename = savedirhigh + "image_" + str(imageindex) + '.jpg'
    cv2.imwrite(savefilename, image)

    # load and display captions
    annIds = coco_caps.getAnnIds(imgIds=img['id']);
    anns = coco_caps.loadAnns(annIds)
    #print(coco_caps.showAnns(anns))

    index = 3 # Choosing 1st caption
    caption = anns[index]['caption']
    captionfile.write(caption + '\n')

    #====Downsample=====================
    '''
    image = cv2.imread(savefilename)

    image_res = cv2.resize(image,(low_res,low_res))
    savefilename = savedirlow + "image_" + str(imageindex) + '.jpg'

    cv2.imwrite(savefilename, image_res)
    '''
    return 1

# initialize COCO API for instance annotations
dataDir = 'Datasets/'
dataType = 'train2017'

highres = "HighRes"
lowres = "LowRes"

savedirhigh = dataDir + "extracted_images/motion_cocoAPI/" + highres + "/"
savedirlow = dataDir + "extracted_images/motion_cocoAPI/" + lowres + "/"

captionfilename = dataDir + "extracted_images/motion_cocoAPI/captions.txt"
jf = open(dataDir + 'annotations/captions_train2017.json')
captionsjson = json.load(jf)

image_src_Coco = dataDir + dataType + "/"

if not os.path.exists(savedirhigh):
	os.makedirs(savedirhigh)

if not os.path.exists(savedirlow):
	os.makedirs(savedirlow)

instances_annFile = os.path.join(dataDir, 'annotations/instances_{}.json'.format(dataType))
coco = COCO(instances_annFile)

# initialize COCO API for caption annotations
captions_annFile = os.path.join(dataDir, 'annotations/captions_{}.json'.format(dataType))
coco_caps = COCO(captions_annFile)

# get image ids
ids = list(coco.anns.keys())

#category_list = [["person", "skateboard"]]

category_list = [["person", "skateboard"], ["person", "surfboard"], ["person", "snowboard"], ["person", "baseball bat"], ["person", "frisbee"], ["person", "kite"], ["person", "sports ball"],["person", "tennis racket"]]

numcategories =  len(category_list)

print(f"Total # of categories given = {numcategories}")

per_category_image = 1250

imageCountWanted = numcategories * per_category_image

print(f"Total # of image want to extract = {imageCountWanted}")

captionfile = open(captionfilename, "w")

imageindex = 0

for c in range(numcategories):

	cat_Ids= coco.getCatIds(catNms= category_list[c])

	catCount = len(cat_Ids)

	if catCount > 0:

		image_Ids = coco.getImgIds(catIds = cat_Ids)

		imageCount = len(image_Ids)

		if imageCount > 0:
			print(f"Found {imageCount} images based on the category list = {category_list[c]}")

			for i in range (min(imageCount,per_category_image)):
				#index = np.random.choice(image_Ids)
				flag = loadImageandCaption(image_Ids[i],imageindex)
				imageindex += flag


		else:
			print(f"No images found based on the category list = {category_list[c]}")
	else:
		print(f"No categories found based on the category list = {category_list[c]}")

print(f"Total # of image extracted = {imageindex}")

captionfile.close()
jf.close()
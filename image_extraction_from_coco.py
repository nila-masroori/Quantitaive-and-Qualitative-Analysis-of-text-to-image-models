# -*- coding: utf-8 -*-
"""image extraction from COCO.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17WNfS1fRuP1vgmk-mFexdCPTKKMFAoVh
"""

import os

import time
from matplotlib import pyplot as plt
from PIL import Image, ImageDraw
import os
from PIL import ImageFont
import io

import cv2
import json
import mediapipe as mp
import cv2
import re


def extractImages(image_src_Coco,save_dir,processed_images, num_images_wanted,mapping,captions,captionfile, low_res = 512):

	words_of_interest = ['running', 'swimming', 'riding', 'falling', 'throwing', 'jumping', 'walking', 'chasing']


	count = 0

	for cap in captions['annotations'][0:50000]: #[3000:7000]:
		if count >= num_images_wanted:
			break

		interesting = any([w.lower() in cap['caption'].lower().split() for w in words_of_interest])
		#interesting = any(re.findall(r'\b(\w+ing)\b',cap['caption'].lower()))

		#print(interesting)

		if not interesting:
			continue

		f_name = captions['images'][mapping[cap['image_id']]]['file_name']

		if f_name in processed_images:
			continue

		captiontext = cap['caption']
		#print(cap)
		captionfile.write(captiontext + '\n')

		image = cv2.imread(os.path.join(image_src_Coco,f_name))
		plt.imshow(image)
		plt.show()

		#image_res = cv2.resize(image,(low_res,low_res))

		savefilename = save_dir + "image_" + str(count) + '.jpg'

		cv2.imwrite(savefilename, image)
		count += 1

		processed_images.add(f_name)


	#print(processed_images)
	return processed_images, count


if __name__ == '__main__':

	path = "Datasets/"

	image_src_Coco = path + "train2017/"
	save_dir = path + "extracted_images/motion_Analysis/"

	if not os.path.exists(save_dir):
		os.makedirs(save_dir)

	captionfilename = path + "extracted_images/motion_Analysis/captions.txt"
	captionfile = open(captionfilename, "w")

	jf = open(path + 'annotations/captions_train2017.json')
	captions = json.load(jf)

	#print(captions['annotations'][0])

	numcaptions = len(captions['annotations'])
	numimages = len(captions['images'])

	print(f"Total # of captions = {numcaptions}")
	print(f"Total # of images = {numimages}")

	#assert numcaptions == numimages * 5

	#print("Ok")

	mapping = {}
	for idx,cap in enumerate(captions['images']):
		mapping[cap['id']] = idx

	processed_images = set()
	num_images_wanted = 300
	face_res = 512

	processed_images, images_generated = extractImages(image_src_Coco,save_dir, processed_images, num_images_wanted,mapping,captions,captionfile)
	print(f'{images_generated} images were generated ')

	#x = prune_detected_faces((f'{save_dir}/faces{n}'))
	#print(f'{x} images were removed')


	captionfile.close()
	jf.close()
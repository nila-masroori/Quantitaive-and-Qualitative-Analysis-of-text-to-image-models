# -*- coding: utf-8 -*-
"""Stable Diffusion image generation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1oRyJ8uzWQsv9OBYVLlpeCpz3kN-H96f5
"""

from google.colab import drive
drive.mount('/content/drive/')

!pip install diffusers

# make sure you're logged in with `huggingface-cli login`
import torch
from torch import autocast
from diffusers import StableDiffusionPipeline
from PIL import Image
import time

def image_grid(imgs, rows, cols):
    assert len(imgs) == rows*cols

    w, h = imgs[0].size
    grid = Image.new('RGB', size=(cols*w, rows*h))
    grid_w, grid_h = grid.size

    for i, img in enumerate(imgs):
        grid.paste(img, box=(i%cols*w, i//cols*h))
    return grid

# !pip uninstall transformers
!pip install transformers

import transformers
print(transformers.__version__)

!pip uninstall transformers
!pip install transformers

YOUR_TOKEN="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"
# pipe = StableDiffusionPipeline.from_pretrained("CompVis/stable-diffusion-v1-4", use_auth_token=YOUR_TOKEN,revision="fp16", torch_dtype=torch.float16).to("cuda")

pipe = StableDiffusionPipeline.from_pretrained(
	"CompVis/stable-diffusion-v1-4",
	revision="fp16", torch_dtype=torch.float16,
	use_auth_token=YOUR_TOKEN
).to("cuda")


code = 1
num_steps=50 #Default value
generator = torch.Generator("cuda:2").manual_seed(1024)
# for f in range(1,16):
#   if code == 1:
#     captionfile = "/content/race-bias.txt"
#     count = 0
#     with open(captionfile, 'r') as readfile:
#           for caption in readfile:
#             # while count < 10000:
#                 prompt = caption.rstrip()
#                 print(prompt)

#                 # The other parameter in the pipeline call is guidance_scale. It is a way to increase the adherence to the
#                 # conditional signal which in this case is text as well as overall sample quality. In simple terms
#                 # classifier free guidance forces the generation to better match with the prompt. Numbers like 7 or 8.5
#                 # give good results, if you use a very large number the images might look good, but will be less diverse.
#                 start = time.time()
prompt = "a photograph of an astronaut riding a horse"

for i in range(1):
    with autocast("cuda"):
        # image = pipe(prompt,guidance_scale=5.5, generator=generator,num_inference_steps=num_steps).images[0]
        image = pipe(prompt, guidance_scale=7.5, num_inference_steps=num_steps).images[0]

    image.save("/content/drive/MyDrive/Project-AML/" + prompt + str(f) + ".jpg")


                # end = time.time()

                # ttime = float("{:.2f}".format(end - start))
                # print(f"Time taken = {ttime}")
                # count += 1

                # if count == 3:
                #     break
  # else:
  #     num_rows = 1
  #     num_cols = 2

# prompt = ["a photograph of an astronaut riding a horse"]

# all_images = []
# for i in range(num_rows):
#     images = pipe(prompt, guidance_scale=7.5, num_inference_steps=num_steps).images
#     all_images.extend(images)

# grid = image_grid(all_images, rows=num_rows, cols=num_cols)
# grid.save("images/grid_astronaut_rides_horse.png")

import os

len(os.listdir("/content/drive/MyDrive/Project-AML/New Bias/Stable diffusion"))

